{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Software para generación de anotaciones en formato YOLOv4\n",
        "* **Autor:** Julian Zuloaga\n",
        "* **Asignatura:** Proyecto Electrónico\n",
        "* **Fecha:** 03 de julio de 2022\n",
        "---"
      ],
      "metadata": {
        "id": "VA2JiToLQ6rG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Descripción:** Este cuaderno de Google Colab presenta la implementación de un software para convertir bases de datos para FER al formato YOLOv4. En este caso, la demostración se realiza con un extracto de la base de datos AffectNet, sin embargo, adaptar el código de este programa para ser utilizado con otras bases de datos es muy fácil.\n",
        "\n",
        "* **Nota: Se recomienda hacer una copia de este cuaderno en su unidad de Google Drive personal antes de ejecutar las celdas de código.**\n",
        "---"
      ],
      "metadata": {
        "id": "EL5_fj6e2pfH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Se importan recursos\n",
        "El primer paso es cargar los archivos y recursos necesarios para el funcionamiento del programa."
      ],
      "metadata": {
        "id": "8pYuOisZmmZu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A578sDm_-BJ9"
      },
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# Se importan librerías para procesamiento de imágenes\n",
        "from PIL import Image\n",
        "import ntpath\n",
        "import os\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UlRIVhaYPd8"
      },
      "source": [
        "# Se clona el repositorio con Darknet\n",
        "!git clone https://github.com/AlexeyAB/darknet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGNvNdcX9rGp",
        "outputId": "dc2718f5-177a-4ca0-d568-87f40c5ab68b"
      },
      "source": [
        "# Se modifica el archivo makefile para habilitar GPU, OPENCV y LIBSO\n",
        "%cd darknet\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
        "!sed -i 's/LIBSO=0/LIBSO=1/' Makefile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/darknet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5ogzikW9wk6"
      },
      "source": [
        "# Se construye Darknet para contar con el archivo darknet.py junto con sus dependencias\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se descargan desde GDrive los pesos del modelo Yolov4 para Detección Facial que se entrenó en la asignatura Proyecto Electrónico\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1emhZyDxGmHWp2UuIpYdi59UuoJxYRc5B' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1emhZyDxGmHWp2UuIpYdi59UuoJxYRc5B\" -O yolov4-csp.weights && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "id": "r1Aq7aZhwIKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea el directorio custom_model en la carpeta darkent\n",
        "!mkdir /darknet/ custom_model"
      ],
      "metadata": {
        "id": "0szpoBkt3rXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Luego se descarga el archivo de configuración yolov4-csp.cfg\n",
        "!wget \"https://drive.google.com/uc?export=download&id=1qTLjZIVRMLklWAcZhdF09x_pLvTWxw1y\" -O yolov4-csp.cfg\n",
        "# Se mueve el archivo de configuración a la carpeta \"custom_model\"\n",
        "!cp yolov4-csp.cfg ../darknet/custom_model/"
      ],
      "metadata": {
        "id": "RRUNn2I8ytCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Después, se descargan los archivos obj.names y obj.data, y se copian en sus respectivas carpetas\n",
        "!wget \"https://drive.google.com/uc?export=download&id=1OkzofUrQInBNKszZSwa88EZr2rojYqLr\" -O obj.names\n",
        "!wget \"https://drive.google.com/uc?export=download&id=1R1XdN8QyaneplyWTAkD1DojV9_jCyzUD\" -O obj.data\n",
        "# Se mueve el archivo de configuración a la carpeta \"custom_model\"\n",
        "!cp obj.names ../darknet/custom_model/\n",
        "!cp obj.data ../darknet/custom_model/\n",
        "# Adicionalmente, se copia el archivo .names a la carpeta data\n",
        "!cp obj.names ../darknet/data/"
      ],
      "metadata": {
        "id": "-m8cF9dn4uHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se copian los archivos de configuración a la carpeta cfg\n",
        "!cp obj.data ../darknet/cfg/\n",
        "!cp obj.names ../darknet/cfg/\n",
        "!cp yolov4-csp.cfg ../darknet/cfg/"
      ],
      "metadata": {
        "id": "9shFvhj3GBiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5o5Gs75ZuMv"
      },
      "source": [
        "## 2) Se definen funciones auxiliares de Darknet para Python\n",
        "Para utilizar YOLOv4 con Python, se usará algunas de las funciones integradas que posee este framework, las cuales están contenidas en el archivo darknet.py. Para ello, se importarán estas funciones al espacio de trabajo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhrQqPc2HR27"
      },
      "source": [
        "# Se importan las funciones de Darknet\n",
        "from darknet import *\n",
        "# Se carga nuestra red perzonalizada de YOLOv4 para Detección de Rostros\n",
        "network, class_names, class_colors = load_network(\"cfg/yolov4-csp.cfg\", \"cfg/obj.data\", \"yolov4-csp.weights\")\n",
        "\n",
        "# Se calculan las dimensiones de entrada de la red neuronal\n",
        "width = network_width(network)\n",
        "height = network_height(network)\n",
        "\n",
        "# Se define función auxiliar para ejecutar detecciones con la red neuronal\n",
        "def darknet_helper(img, width, height):\n",
        "  darknet_image = make_image(width, height, 3) # imagen en formato Darknet\n",
        "  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # se pasa imagen de BGR a RGB\n",
        "  img_resized = cv2.resize(img_rgb, (width, height), # Se escala imagen a dimensiones de entrada de la red\n",
        "                              interpolation=cv2.INTER_LINEAR)\n",
        "  # Se obtienen las relaciones para convertir bounding boxes al tamaño real de la imagen\n",
        "  img_height, img_width, _ = img.shape # tamaño imagen\n",
        "  width_ratio = img_width/width # razón de ancho = ancho imagen/ancho entrada red\n",
        "  height_ratio = img_height/height\n",
        "\n",
        "  # Se ejecutan las detecciones con la red sobre la imagen entregada\n",
        "  copy_image_from_bytes(darknet_image, img_resized.tobytes())\n",
        "  detections = detect_image(network, class_names, darknet_image)\n",
        "  free_image(darknet_image)\n",
        "  return detections, width_ratio, height_ratio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymeEhEnFbsdm"
      },
      "source": [
        "## 3) Prueba de detección facial con YOLOv4\n",
        "Se ejecuta una detección de prueba para verificar que nuestra red de YOLOv4 para detectar rostros en imágenes ha sido cargada correctamente.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se descarga imagen de prueba\n",
        "!wget \"https://drive.google.com/uc?export=download&id=1YIF--yDHT3QCvCxOxf12mpBbDpy5S3ri\" -O portrait.jpg\n",
        "!cp portrait.jpg ../darknet/data/"
      ],
      "metadata": {
        "id": "GNWSlixTj0GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwfFDhs5TMhi"
      },
      "source": [
        "# Se ejecuta la prueba sobre la imagen portrait.jpg\n",
        "image = cv2.imread(\"data/portrait.jpg\") # se abre la imagen con cv2\n",
        "detections, width_ratio, height_ratio = darknet_helper(image, width, height) # Se ejecuta la detección sobre la imagen\n",
        "# Se generan bounding boxes sobre las detecciones\n",
        "for label, confidence, bbox in detections:\n",
        "  left, top, right, bottom = bbox2points(bbox) #coordenadas del bounding box\n",
        "  # se convierte cooredenadas en formato YOLO a cordenadas de la imagen cargada\n",
        "  left, top, right, bottom = int(left * width_ratio), int(top * height_ratio), int(right * width_ratio), int(bottom * height_ratio)\n",
        "  # se genera rectángulo sobre las coordenadas obtenidas\n",
        "  cv2.rectangle(image, (left, top), (right, bottom), class_colors[label], 2)\n",
        "  # Se escribe clase junto con probabilidad de confianza\n",
        "  cv2.putText(image, \"{} [{:.2f}]\".format(label, float(confidence)),\n",
        "                    (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 1.2,\n",
        "                    class_colors[label], 2)\n",
        "cv2_imshow(image) # se muestra la imagen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Se descarga la base de datos AffectNet\n",
        "Se descarga el comprimido con el extracto de la base de datos AffectNet que se convertirá a formato YOLOv4."
      ],
      "metadata": {
        "id": "4pHnS05MnD8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se descarga la base de datos AffectNet\n",
        "%cd /content/\n",
        "!mkdir \"dataset\" # se crea carpeta \"dataset\"\n",
        "# EN ESTE PASO, CARGUE SU VERSIÓN DE AFFECTNET EN \"/content/dataset/AffectNet_JPG_formated.zip\"\n",
        "# Se descomprime la base de datos\n",
        "%cd /content/dataset/\n",
        "!unzip /content/dataset/AffectNet_JPG_formated.zip\n",
        "!rm /content/dataset/AffectNet_JPG_formated.zip #se borra el comprimido\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "FyRE1g9bole-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Configuración del procesador de imágenes\n",
        "\n",
        "Ahora se establecen algunos parámetros importantes para el funcionamiento del programa que genera las anotaciones de la base de datos cargada, como los directorios de entrada y salida."
      ],
      "metadata": {
        "id": "Mc99hqNnnT9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea directorio de destino\n",
        "!mkdir \"/content/YOLOv4_formatted_dataset\""
      ],
      "metadata": {
        "id": "fQw-mx8jSeTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se define dirección de entrada y salida del sistema de procesamiento\n",
        "data_dir = \"/content/dataset/\" # entrada\n",
        "output_dir = \"/content/YOLOv4_formatted_dataset/\" # salida\n",
        "# Se extraen las subdirecciones de las carpetas con las clases\n",
        "zz = [x[0] for x in os.walk(data_dir)]\n",
        "print(f\"Se han encontrado {len(zz)-1} clases:\")\n",
        "# Se extraen los nombres de las clases\n",
        "lista_clases = list() #Se inicializa lista con nombre de clases\n",
        "# Se imprimen las clases encontradas\n",
        "for j in range(1,len(zz)):\n",
        "\tlista_clases.append(ntpath.basename(zz[j]))\n",
        "\tprint(f'{ntpath.basename(zz[j])}')\n",
        " \n",
        "#se define lista con las clases de la base de datos en orden alfabético\n",
        "classes_names = [\"anger\",\"contempt\",\"disgust\",\"fear\",\"happy\",\"neutral\",\"sad\",\"surprise\"]\n"
      ],
      "metadata": {
        "id": "q6cZFXz8bkb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crean subdirectorios obj y test en carpeta de destino\n",
        "os.mkdir(output_dir+\"/test\")\n",
        "os.mkdir(output_dir+\"/obj\")"
      ],
      "metadata": {
        "id": "mQD6F88CKXFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Se ejecuta la conversión de formatos\n",
        "Luego, se procede a ejecutar la conversión."
      ],
      "metadata": {
        "id": "DTOnad5vnjvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se comienza con la conversión de las imágenes\n",
        "# se definen las clases en el orden que acepta YOLOv4 para FER (obj.names)\n",
        "img_dir = list() # se inicializa lista con directorio de imágenes\n",
        "img_path = \"\" #se inicializa string con directorio de imagen\n",
        "contador_errores = 0 #se cuentan las imágenes no convertidas\n",
        "lista_errores = list() #lista para llevar seguimiento de los errores de conversión\n",
        "porcen_train = 0.85 #se define % de imágenes del dataset para entrenamiento\n",
        "porcen_test = 1-porcen_train # se define % de imágenes para validación\n",
        "img_name_counter = 1 # contador de imágenes para asignar nombre\n",
        "# Se itera la lista de clases\n",
        "for j in lista_clases:\n",
        "    # Se llena la lista con las direcciones de las imágenes de una clase\n",
        "    img_dir = glob.glob(data_dir+j+\"/*.jpg\")\n",
        "    # e calculan imágenes para entrenamiento y validación\n",
        "    n_img_train = int(len(img_dir)*porcen_train)\n",
        "    n_img_test = int(len(img_dir)-n_img_train)\n",
        "    print(f\"Total de imágenes en '{j}' es: {len(img_dir)}. Imágenes para entrenamiento: {n_img_train}, validación: {n_img_test}.\")\n",
        "    img_counter = 1 # contador de imágenes procesadas por clase para división de dataset\n",
        "    # Se itera la lista de imágenes de una clase\n",
        "    for i in img_dir:\n",
        "      # Se abre la imagen con Pillow\n",
        "      img = Image.open(i)\n",
        "      # Se obtiene las dimensiones de la imagen\n",
        "      img_width, img_height = img.size #(width, height)\n",
        "      # se obtiene el nombre de la imagen sin la extensión\n",
        "      #img_name = (os.path.split(i[:-4])[-1])\n",
        "      # Se asigna nombre a la imagen con el número y clase\n",
        "      img_name = img_name_counter\n",
        "      # Se lee la imagen con cv2\n",
        "      img_cv2 = cv2.imread(i) # se abre la imagen con cv2\n",
        "      # Se ejecuta detección\n",
        "      detections, width_ratio, height_ratio = darknet_helper(img_cv2, width, height) # Se ejecuta la detección sobre la imagen\n",
        "      # Se generan bounding boxes sobre las detecciones\n",
        "      for label, confidence, bbox in detections:\n",
        "        left, top, right, bottom = bbox2points(bbox) #coordenadas del bounding box\n",
        "        # se convierte cooredenadas en formato YOLO a cordenadas de la imagen cargada\n",
        "        left, top, right, bottom = int(left * width_ratio), int(top * height_ratio), int(right * width_ratio), int(bottom * height_ratio)\n",
        "      # Se calculan parámetros para archivo de texto:\n",
        "      param1 = classes_names.index(j) # clase\n",
        "      param2 = (((right - left)/2) + left)*(1/img_width) # Centro horizontal normalizado\n",
        "      param3 = ((bottom - top)/2 + top)*(1/img_height) # Centro vertical normalizado\n",
        "      param4 = (right - left)/img_width # ancho bbox normalizado\n",
        "      param5 = (bottom - top)/img_height # alto bbox normalizado\n",
        "      # Se guardan las coordenadas en un archivo de texto\n",
        "      if img_counter <= n_img_train:\n",
        "        img_txt = open(output_dir + \"obj/\" + str(img_name) + \".txt\",'w')\n",
        "        cv2.imwrite(output_dir + \"obj/\" + str(img_name) + \".jpg\", img_cv2)\n",
        "      else:\n",
        "        img_txt = open(output_dir + \"test/\" + str(img_name) + \".txt\",'w')\n",
        "        cv2.imwrite(output_dir + \"test/\" + str(img_name) + \".jpg\", img_cv2)\n",
        "      # Se escriben los parámetros en el archivo de text\n",
        "      img_txt.write(f'{param1} {param2} {param3} {param4} {param5}')\n",
        "      # Se cierra el archivo de texto\n",
        "      img_txt.close()\n",
        "      #Se cierra la imagen abierta con pillow\n",
        "      img.close()\n",
        "      #Se incrementan los contadores de imágenes procesadas\n",
        "      img_counter = img_counter + 1\n",
        "      img_name_counter = img_name_counter + 1\n",
        "      \n",
        "print(\"Conversión Finalizada!!\")"
      ],
      "metadata": {
        "id": "H-Lqz5Gue6Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Guardado de la base de datos convertida\n",
        "Posterior a la conversión, se procede a guardar la base de datos generada."
      ],
      "metadata": {
        "id": "WKbCgFFqoJ8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se comprime el dataset obtenido\n",
        "!zip -r /content/YOLOv4_formatted_dataset.zip /content/YOLOv4_formatted_dataset"
      ],
      "metadata": {
        "id": "-O7GIGi_MIar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí hay 2 opciones para guardar la base de datos convertida, la primera opción es descargarla directamente a la computador del Host, desde la Cloud VM de Google Colab, aunque esta opción es bastante lenta. La segunda opción y la más recomendada, es montar una unidad de Google Drive y copiar el archivo directamente a la unidad, lo cual es mucho más rápido."
      ],
      "metadata": {
        "id": "2quVthYhoiNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se define función auxiliar para descargar modelo de pesos desde la Cloud VM al computador local\n",
        "def download(path):\n",
        "  from google.colab import files\n",
        "  files.download(path)"
      ],
      "metadata": {
        "id": "6FSf8zXVMtVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se descarga el dataset guardado al computador local\n",
        "download(\"/content/YOLOv4_formatted_dataset.zip\")\n",
        "\n",
        "# Nota: El .zip contiene el dataset en la estructura: content > cropped_dataset > angry, contempt, disgust, etc."
      ],
      "metadata": {
        "id": "7g0tHyOIM6Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se monta unidad de GDrive para copiar más rápido el Dataset comprimido\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WXryGHczcxDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea un symbolic link para simplificar escritura de directorio\n",
        "!ln -s /content/drive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive"
      ],
      "metadata": {
        "id": "GX12fx--dMYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se copia el dataset al GDrive\n",
        "!cp /content/YOLOv4_formatted_dataset.zip /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "3bDiu4L8dPCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con eso concluye la implementación del software. Muchas Gracias."
      ],
      "metadata": {
        "id": "C8vU4Qnu3YAi"
      }
    }
  ]
}